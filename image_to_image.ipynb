{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate imports, trim later\n",
    "import math\n",
    "from random import sample\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "import cv2\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing  (1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(filepath, start_frame=0, end_frame=-1):\n",
    "    # import video\n",
    "    video = cv2.VideoCapture(filepath)\n",
    "    # get frame size (to size array) and number of frames\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/ resizing image\n",
    "    scale_percent = 50\n",
    "    width = int(frame_width * scale_percent / 100)\n",
    "    height = int(frame_height * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    \n",
    "    if end_frame == -1 or end_frame > frame_count:\n",
    "        end_frame = frame_count\n",
    "\n",
    "    frames = np.empty((end_frame-start_frame, height, width, 3), np.dtype('uint8'))\n",
    "\n",
    "    for frame in range(start_frame,min(end_frame,frame_count)):\n",
    "        success, img = video.read()\n",
    "        if not success: break\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # reduce image size to help model memory\n",
    "        frames[frame] = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    video.release()\n",
    "    return frames\n",
    "\n",
    "def load_video_random_frames(filepath, number_of_frames):\n",
    "    # import video\n",
    "    video = cv2.VideoCapture(filepath)\n",
    "    # get frame size (to size array) and number of frames\n",
    "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/ resizing image\n",
    "    scale_percent = 50\n",
    "    width = int(frame_width * scale_percent / 100)\n",
    "    height = int(frame_height * scale_percent / 100)\n",
    "    dim = (width, height)                  \n",
    "    \n",
    "    frames = np.empty((number_of_frames, height, width, 3), np.dtype('uint8'))\n",
    "    \n",
    "    used_frames = []\n",
    "    for frame in range(number_of_frames):\n",
    "        num = randint(0,frame_count-1)\n",
    "        while True:\n",
    "            if num not in used_frames:\n",
    "                used_frames.append(num)\n",
    "                break\n",
    "            num = randint(0,frame_count-1)\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES,num);\n",
    "        success, img = video.read()\n",
    "        if not success: break\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # reduce image size to help model memory\n",
    "        frames[frame] = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "                     \n",
    "    video.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAFIA_FILEPATH = \"datasets/game/MafiaVideogame.mp4\"\n",
    "GODFATHER_FILEPATH = \"datasets/movie/TheGodfather.mp4\"\n",
    "IRISHMAN_FILEPATH = \"datasets/movie/TheIrishman.mp4\"\n",
    "SOPRANOS_FILEPATH = \"datasets/movie/TheSopranos.mp4\"\n",
    "\n",
    "MAFIA_FRAMES = load_video_random_frames(MAFIA_FILEPATH,10)\n",
    "#GODFATHER_FRAMES = load_video_random_frames(GODFATHER_FILEPATH)\n",
    "#IRISHMAN_FRAMES = load_video_random_frames(IRISHMAN_FILEPATH)\n",
    "#SOPRANOS_FRAMES = load_video_random_frames(SOPRANOS_FILEPATH)\n",
    "\n",
    "\"\"\"\n",
    "# view frames\n",
    "count = 0\n",
    "for frame in MAFIA_FRAMES:\n",
    "    cv2.namedWindow(f'frame {count}')\n",
    "    cv2.imshow(f'frame {count}', frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow(f'frame {count}')\n",
    "    count+=1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame-to-Frame Model (2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        channels = 3\n",
    "        nf = 64\n",
    "        \n",
    "        def downsample_convolution(in_features, out_features):\n",
    "            return nn.Sequential(nn.Conv2d(in_features, out_features, 4, 2, 1),\n",
    "                        nn.InstanceNorm2d(out_features*2),\n",
    "                        nn.LeakyReLU(0.2))\n",
    "        \n",
    "        def residual_convolution(in_features):\n",
    "             return nn.Sequential(nn.Conv2d(in_features, in_features, 3, 1, 1),\n",
    "                                  nn.Conv2d(in_features, in_features, 3, 1, 1))\n",
    "        \n",
    "        def upsample_convolution(in_features, out_features):\n",
    "            return nn.Sequential(nn.ConvTranspose2d(in_features, out_features, 4, 2, 1),\n",
    "                        nn.InstanceNorm2d(out_features, 0.8),\n",
    "                        nn.ReLU())\n",
    "            \n",
    "            \n",
    "        self.conv1 = nn.Sequential(\n",
    "                    nn.Conv2d(channels, nf, 4, 2, 1),\n",
    "                    nn.LeakyReLU())\n",
    "        self.downsample1 = downsample(nf,nf*2)\n",
    "        self.residual1 = residual_convolution(nf*2)\n",
    "        \n",
    "        self.downsample2 = downsample(nf*2,nf*4)\n",
    "        self.residual2 = residual_convolution(nf*4)\n",
    "        self.upsample1 = upsample_convolution(nf*4, nf*2)\n",
    "        \n",
    "        self.residual3 = residual_convolution(nf*2)\n",
    "        self.upsample2 = upsample_convolution(nf*2, nf)\n",
    "        self.conv2 = nn.Sequential(\n",
    "                    nn.ConvTranspose2d(nf, channels, 4, 2, 1),\n",
    "                    nn.Tanh())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        pre_residual1_x = self.downsample1(x)\n",
    "        x = torch.cat([pre_residual1_x, self.residual1(pre_residual1_x)], dim=1)\n",
    "        pre_residual2_x = self.downsample2(x)\n",
    "        x = torch.cat([pre_residual2_x, self.residual2(pre_residual2_x)], dim=1)\n",
    "        pre_residual3_x = self.upsample1(x)\n",
    "        x = torch.cat([pre_residual3_x, self.residual3(pre_residual3_x)], dim=1)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
