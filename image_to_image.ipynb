{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "image_to_image.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TAUjvVEt1l91",
        "VuqnpxgJ1ogM"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q71uadXqx8JC"
      },
      "source": [
        "# boilerplate imports, trim later\n",
        "import math\n",
        "from random import sample\n",
        "from random import randint\n",
        "\n",
        "!pip install comet-ml &> /dev/null\n",
        "import comet_ml\n",
        "\n",
        "!pip install pytorch-lightning &> /dev/null\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import CometLogger\n",
        "import tensorboard\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import cv2\n",
        "\n",
        "!pip install pytorch-msssim &> /dev/null\n",
        "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from livelossplot import PlotLosses\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcIpkAP2x8JD"
      },
      "source": [
        "# Preprocessing  (1.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y3lIONBx8JE"
      },
      "source": [
        "def load_video(filepath, start_frame=0, end_frame=-1):\n",
        "    # import video\n",
        "    video = cv2.VideoCapture(filepath)\n",
        "    # get frame size (to size array) and number of frames\n",
        "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    \n",
        "    # https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/ resizing image\n",
        "    scale_percent = 50\n",
        "    width = int(frame_width * scale_percent / 100)\n",
        "    height = int(frame_height * scale_percent / 100)\n",
        "    dim = (width, height)\n",
        "    \n",
        "    if end_frame == -1 or end_frame > frame_count:\n",
        "        end_frame = frame_count\n",
        "\n",
        "    frames = np.empty((end_frame-start_frame, height, width, 3), np.dtype('uint8'))\n",
        "\n",
        "    for frame in range(start_frame,min(end_frame,frame_count)):\n",
        "        success, img = video.read()\n",
        "        if not success: break\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        # reduce image size to help model memory\n",
        "        frames[frame] = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    video.release()\n",
        "    return frames\n",
        "\n",
        "def load_video_random_frames(filepath, number_of_frames):\n",
        "    # import video\n",
        "    video = cv2.VideoCapture(filepath)\n",
        "    # get frame size (to size array) and number of frames\n",
        "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    \n",
        "    # https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/ resizing image\n",
        "    scale_percent = 10 # 120x72 image size\n",
        "    width = int(frame_width * scale_percent / 100)\n",
        "    height = int(frame_height * scale_percent / 100)\n",
        "    dim = (width, height)                  \n",
        "    \n",
        "    frames = np.empty((number_of_frames, height, width, 3), np.dtype('uint8'))\n",
        "    \n",
        "    used_frames = []\n",
        "    for frame in range(number_of_frames):\n",
        "        num = randint(0,frame_count-1)\n",
        "        while True:\n",
        "            if num not in used_frames:\n",
        "                used_frames.append(num)\n",
        "                break\n",
        "            num = randint(0,frame_count-1)\n",
        "        video.set(cv2.CAP_PROP_POS_FRAMES,num);\n",
        "        success, img = video.read()\n",
        "        if not success: break\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        # reduce image size to help model memory\n",
        "        frames[frame] = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "                     \n",
        "    video.release()\n",
        "    return frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li959gprx8JF"
      },
      "source": [
        "MAFIA_FILEPATH = \"datasets/game/MafiaVideogame.mp4\"\n",
        "GODFATHER_FILEPATH = \"datasets/movie/TheGodfather.mp4\"\n",
        "IRISHMAN_FILEPATH = \"datasets/movie/TheIrishman.mp4\"\n",
        "SOPRANOS_FILEPATH = \"datasets/movie/TheSopranos.mp4\"\n",
        "\n",
        "MAFIA_FRAMES = load_video_random_frames(MAFIA_FILEPATH,10)\n",
        "#GODFATHER_FRAMES = load_video_random_frames(GODFATHER_FILEPATH)\n",
        "#IRISHMAN_FRAMES = load_video_random_frames(IRISHMAN_FILEPATH)\n",
        "#SOPRANOS_FRAMES = load_video_random_frames(SOPRANOS_FILEPATH)\n",
        "\n",
        "\"\"\"\n",
        "# view frames\n",
        "count = 0\n",
        "for frame in MAFIA_FRAMES:\n",
        "    cv2.namedWindow(f'frame {count}')\n",
        "    cv2.imshow(f'frame {count}', frame)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyWindow(f'frame {count}')\n",
        "    count+=1\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhNJ8ulfx8JG"
      },
      "source": [
        "# Frame-to-Frame Model (2.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAUjvVEt1l91"
      },
      "source": [
        "##Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl-Nc4NA9rZJ"
      },
      "source": [
        "# used pytorch lightning to make the model neater, code layout from here: https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#minimal-example\n",
        "class Generator(pl.LightningModule):\n",
        "    def __init__(self, learning_rate=1e-2):\n",
        "        super().__init__()\n",
        "        channels = 3\n",
        "        nf = 64\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        def downsample_convolution(in_features, out_features):\n",
        "                return nn.Sequential(\n",
        "                            nn.Conv2d(in_features, out_features, 4, 2, 1),\n",
        "                            nn.InstanceNorm2d(out_features*2),\n",
        "                            nn.LeakyReLU(0.2))\n",
        "            \n",
        "        def residual_convolution(in_features):\n",
        "            return nn.Sequential(nn.Conv2d(in_features, in_features, 3, 1, 1),\n",
        "                                nn.Conv2d(in_features, in_features, 3, 1, 1))\n",
        "            \n",
        "        def upsample_convolution(in_features, out_features):\n",
        "            return nn.Sequential(n\n",
        "                        n.ConvTranspose2d(in_features, out_features, 4, 2, 1),\n",
        "                        nn.InstanceNorm2d(out_features, 0.8),\n",
        "                        nn.ReLU())\n",
        "            \n",
        "            \n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(channels, nf, 4, 2, 1),\n",
        "                        nn.LeakyReLU())\n",
        "        self.downsample1 = downsample(nf,nf*2)\n",
        "        self.residual1 = residual_convolution(nf*2)\n",
        "        \n",
        "        self.downsample2 = downsample(nf*2,nf*4)\n",
        "        self.residual2 = residual_convolution(nf*4)\n",
        "        self.upsample1 = upsample_convolution(nf*4, nf*2)\n",
        "        \n",
        "        self.residual3 = residual_convolution(nf*2)\n",
        "        self.upsample2 = upsample_convolution(nf*2, nf)\n",
        "        self.conv2 = nn.Sequential(\n",
        "                    nn.ConvTranspose2d(nf, channels, 4, 2, 1),\n",
        "                    nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        pre_residual1_x = self.downsample1(x)\n",
        "        x = torch.cat([pre_residual1_x, self.residual1(pre_residual1_x)], dim=1)\n",
        "        pre_residual2_x = self.downsample2(x)\n",
        "        x = torch.cat([pre_residual2_x, self.residual2(pre_residual2_x)], dim=1)\n",
        "        pre_residual3_x = self.upsample1(x)\n",
        "        x = torch.cat([pre_residual3_x, self.residual3(pre_residual3_x)], dim=1)\n",
        "        x = self.upsample2(x)\n",
        "        x = self.conv2(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        self.log(\"lr\",lr)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        pass\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y = val_batch\n",
        "        y = y.float()\n",
        "        x_hat = self.forward(x)\n",
        "        print(x_hat)\n",
        "        print(y)\n",
        "        loss = self.loss(x_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def test_step(self, batch, idx):\n",
        "        x, y = batch\n",
        "        y = y.float()\n",
        "        x_hat = self.forward(x)\n",
        "        loss = self.loss(x_hat, y)\n",
        "        self.log('test_loss', loss)\n",
        "        accuracy = torch.sum(torch.round(x_hat) == y) / len(y)\n",
        "        self.log('test_acc', accuracy)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuqnpxgJ1ogM"
      },
      "source": [
        "##Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T28GQk3Y9tXc"
      },
      "source": [
        "# used pytorch lightning to make the model neater, code layout from here: https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#minimal-example\n",
        "class Discriminator(pl.LightningModule):\n",
        "    def __init__(self, learning_rate=1e-2):\n",
        "        super().__init__()\n",
        "        nf = 64\n",
        "        channels = 3\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        def dilated_convolution(in_features, out_features, dilation):\n",
        "            return nn.Sequential(nn.Conv2d(in_features, out_features, 4, 1, dilation, dilation),\n",
        "                            nn.InstanceNorm2d(out_features),\n",
        "                            nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        def convolution(in_features, out_features, kernal_size=4, stride=2, padding=1):\n",
        "            return nn.Sequential(nn.Conv2d(in_features, out_features, kernal_size, stride, padding),\n",
        "                            nn.InstanceNorm2d(out_features),\n",
        "                            nn.LeakyReLU(0.2, inplace=True))\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "                    nn.Conv2d(channels, nf, 4, 2, 1),\n",
        "                    nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.layer2 = convolution(nf, nf*2)\n",
        "        self.layer3 = convolution(nf*2, nf*4, 3, 1 , 1)\n",
        "        self.layer4 = dilated_convolution(nf*4, nf*4, 2)\n",
        "        self.layer5 = dilated_convolution(nf*4, nf*4, 4)\n",
        "        self.layer7 = convolution(nf*8, nf*4, 3, 1, 1)\n",
        "        self.layer8 = nn.Conv2d(nf*4, 1, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        layer1 = self.layer1(x)\n",
        "        layer2 = self.layer2(layer1)\n",
        "        layer3 = self.layer3(layer2)\n",
        "        layer4 = self.layer4(layer3)\n",
        "        layer5 = self.layer5(layer4)\n",
        "        layer6 = torch.cat([layer3,layer5], dim=1)\n",
        "        layer7 = self.layer7(layer6)\n",
        "        layer8 = self.layer8(layer7)\n",
        "        return layer8, (layer2, layer3, layer4, layer5, layer7)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        self.log(\"lr\",self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        x, y = train_batch\n",
        "        y = y.float()\n",
        "        x_hat = self.forward(x)\n",
        "        loss = self.loss(x_hat, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y = val_batch\n",
        "        y = y.float()\n",
        "        x_hat = self.forward(x)\n",
        "        print(x_hat)\n",
        "        print(y)\n",
        "        loss = self.loss(x_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def test_step(self, batch, idx):\n",
        "        x, y = batch\n",
        "        y = y.float()\n",
        "        x_hat = self.forward(x)\n",
        "        loss = self.loss(x_hat, y)\n",
        "        self.log('test_loss', loss)\n",
        "        accuracy = torch.sum(torch.round(x_hat) == y) / len(y)\n",
        "        self.log('test_acc', accuracy)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}